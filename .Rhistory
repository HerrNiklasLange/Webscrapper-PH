}
if (testRun == TRUE | as.POSIXlt(Sys.Date())$wday == 0){
#reading most viewed of the country on Yearly on every Sunday
ReadingCountryYearly(ID)
}
if (testRun == TRUE | date == "01"){
#reading country most viewed of all time at the beginning of the month
ReadingCountryAllTime(ID)
}
print(paste("Loop number", i, "done"))
}
#closing the server
remDr$close()
}
ReadingCountryToday <- function(ID){
print(paste("starting country with", ID, "as ID for today"))
newID <- paste("https://www.pornhub.com/video?o=mv&t=t&cc=", ID)
newID <- gsub(" ", "", newID)
remDr$navigate(newID)
updated_page_source <- remDr$getPageSource()[[1]]
# Retrieve the updated page's HTML content
updated_page_source <- remDr$getPageSource()[[1]]
# Parse the updated page's HTML using rvest  https://www.theguardian.com/us
dfWebScrapper <- data.frame(date=c(rep.int(Sys.Date(), 30)), title = "", views = "",likeRatio = "", duration = "", URL = "",featuredOn = "", countryID = "", mostViewed="", position=0)
#reading the data,
for (i in 1:30) {
x <- i + 1
#title
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
Title <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
Title <- gsub("  ", "", Title)
Title <- gsub("\n", "", Title)
dfWebScrapper[[i,2]] <- Title
}
#views
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/span/var")
title_xpath <- gsub(" ", "", title_xpath)
views <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
views <- gsub("  ", "", views)
views <- gsub("\n", "", views)
dfWebScrapper[[i,3]] <- views
}
#likeRatio
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[2]/div/div/div
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/div/div")
title_xpath <- gsub(" ", "", title_xpath)
likeRatio <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
likeRatio <- gsub("  ", "", likeRatio)
likeRatio <- gsub("\n", "", likeRatio)
dfWebScrapper[[i,4]] <- likeRatio
}
#duration
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[1]/a/div/var
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[1]/a/div/var")
title_xpath <- gsub(" ", "", title_xpath)
duration <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
duration <- gsub("  ", "", duration)
duration <- gsub("\n", "", duration)
dfWebScrapper[[i,5]] <- duration
}
#URL
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
URL <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_attr('href')
URL <- gsub("/", "https://www.pornhub.com/", URL)
URL <- gsub(" ", "", URL)
dfWebScrapper[[i,6]] <- URL
}
#featuredOn
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[1]/div/a
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[1]/div/a")
title_xpath <- gsub(" ", "", title_xpath)
featuredOn <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
featuredOn <- gsub("  ", "", featuredOn)
featuredOn <- gsub("\n", "", featuredOn)
dfWebScrapper[[i,7]] <- featuredOn
}
#countryID, mostViewed and position
{
dfWebScrapper[[i,8]] <- ID
dfWebScrapper[[i,9]] <- "today"
dfWebScrapper[[i,10]] <- i
}
}
WritingToExcel(dfWebScrapper)
print("Today done")
}
ReadingCountryWeekly <- function(ID){
print(paste("starting country with", ID, "as ID for Weekly"))
newID <- paste("https://www.pornhub.com/video?o=mv&cc=", ID)
newID <- gsub(" ", "", newID)
remDr$navigate(newID)
updated_page_source <- remDr$getPageSource()[[1]]
# Retrieve the updated page's HTML content
updated_page_source <- remDr$getPageSource()[[1]]
# Parse the updated page's HTML using rvest  https://www.theguardian.com/us
dfWebScrapper <- data.frame(date=c(rep.int(Sys.Date(), 30)), title = "", views = "",likeRatio = "", duration = "", URL = "",featuredOn = "", countryID = "", mostViewed="", position=0)
#reading the data,
for (i in 1:30) {
x <- i + 1
#title
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
Title <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
Title <- gsub("  ", "", Title)
Title <- gsub("\n", "", Title)
dfWebScrapper[[i,2]] <- Title
}
#views
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/span/var")
title_xpath <- gsub(" ", "", title_xpath)
views <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
views <- gsub("  ", "", views)
views <- gsub("\n", "", views)
dfWebScrapper[[i,3]] <- views
}
#likeRatio
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[2]/div/div/div
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/div/div")
title_xpath <- gsub(" ", "", title_xpath)
likeRatio <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
likeRatio <- gsub("  ", "", likeRatio)
likeRatio <- gsub("\n", "", likeRatio)
dfWebScrapper[[i,4]] <- likeRatio
}
#duration
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[1]/a/div/var
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[1]/a/div/var")
title_xpath <- gsub(" ", "", title_xpath)
duration <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
duration <- gsub("  ", "", duration)
duration <- gsub("\n", "", duration)
dfWebScrapper[[i,5]] <- duration
}
#URL
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
URL <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_attr('href')
URL <- gsub("/", "https://www.pornhub.com/", URL)
URL <- gsub(" ", "", URL)
dfWebScrapper[[i,6]] <- URL
}
#featuredOn
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[1]/div/a
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[1]/div/a")
title_xpath <- gsub(" ", "", title_xpath)
featuredOn <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
featuredOn <- gsub("  ", "", featuredOn)
featuredOn <- gsub("\n", "", featuredOn)
dfWebScrapper[[i,7]] <- featuredOn
}
#countryID, mostViewed and position
{
dfWebScrapper[[i,8]] <- ID
dfWebScrapper[[i,9]] <- "weekly"
dfWebScrapper[[i,10]] <- i
}
}
WritingToExcel(dfWebScrapper)
print("Weekly done")
}
ReadingCountryMonthly <- function(ID){
print(paste("starting country with", ID, "as ID for monthly"))
newID <- paste("https://www.pornhub.com/video?o=mv&t=m&cc=", ID)
newID <- gsub(" ", "", newID)
remDr$navigate(newID)
updated_page_source <- remDr$getPageSource()[[1]]
# Retrieve the updated page's HTML content
updated_page_source <- remDr$getPageSource()[[1]]
# Parse the updated page's HTML using rvest  https://www.theguardian.com/us
dfWebScrapper <- data.frame(date=c(rep.int(Sys.Date(), 30)), title = "", views = "",likeRatio = "", duration = "", URL = "",featuredOn = "", countryID = "", mostViewed="", position=0)
#reading the data,
for (i in 1:30) {
x <- i + 1
#title
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
Title <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
Title <- gsub("  ", "", Title)
Title <- gsub("\n", "", Title)
dfWebScrapper[[i,2]] <- Title
}
#views
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/span/var")
title_xpath <- gsub(" ", "", title_xpath)
views <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
views <- gsub("  ", "", views)
views <- gsub("\n", "", views)
dfWebScrapper[[i,3]] <- views
}
#likeRatio
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[2]/div/div/div
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/div/div")
title_xpath <- gsub(" ", "", title_xpath)
likeRatio <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
likeRatio <- gsub("  ", "", likeRatio)
likeRatio <- gsub("\n", "", likeRatio)
dfWebScrapper[[i,4]] <- likeRatio
}
#duration
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[1]/a/div/var
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[1]/a/div/var")
title_xpath <- gsub(" ", "", title_xpath)
duration <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
duration <- gsub("  ", "", duration)
duration <- gsub("\n", "", duration)
dfWebScrapper[[i,5]] <- duration
}
#URL
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
URL <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_attr('href')
URL <- gsub("/", "https://www.pornhub.com/", URL)
URL <- gsub(" ", "", URL)
dfWebScrapper[[i,6]] <- URL
}
#featuredOn
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[1]/div/a
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[1]/div/a")
title_xpath <- gsub(" ", "", title_xpath)
featuredOn <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
featuredOn <- gsub("  ", "", featuredOn)
featuredOn <- gsub("\n", "", featuredOn)
dfWebScrapper[[i,7]] <- featuredOn
}
#countryID, mostViewed and position
{
dfWebScrapper[[i,8]] <- ID
dfWebScrapper[[i,9]] <- "monthly"
dfWebScrapper[[i,10]] <- i
}
}
WritingToExcel(dfWebScrapper)
print("Monthly Done")
}
ReadingCountryYearly <- function(ID){
print(paste("starting country with", ID, "as ID for yearly"))
newID <- paste("https://www.pornhub.com/video?o=mv&t=y&cc=", ID)
newID <- gsub(" ", "", newID)
remDr$navigate(newID)
updated_page_source <- remDr$getPageSource()[[1]]
# Retrieve the updated page's HTML content
updated_page_source <- remDr$getPageSource()[[1]]
# Parse the updated page's HTML using rvest  https://www.theguardian.com/us
dfWebScrapper <- data.frame(date=c(rep.int(Sys.Date(), 30)), title = "", views = "",likeRatio = "", duration = "", URL = "",featuredOn = "", countryID = "", mostViewed="", position=0)
#reading the data,
for (i in 1:30) {
x <- i + 1
#title
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
Title <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
Title <- gsub("  ", "", Title)
Title <- gsub("\n", "", Title)
dfWebScrapper[[i,2]] <- Title
}
#views
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/span/var")
title_xpath <- gsub(" ", "", title_xpath)
views <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
views <- gsub("  ", "", views)
views <- gsub("\n", "", views)
dfWebScrapper[[i,3]] <- views
}
#likeRatio
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[2]/div/div/div
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/div/div")
title_xpath <- gsub(" ", "", title_xpath)
likeRatio <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
likeRatio <- gsub("  ", "", likeRatio)
likeRatio <- gsub("\n", "", likeRatio)
dfWebScrapper[[i,4]] <- likeRatio
}
#duration
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[1]/a/div/var
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[1]/a/div/var")
title_xpath <- gsub(" ", "", title_xpath)
duration <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
duration <- gsub("  ", "", duration)
duration <- gsub("\n", "", duration)
dfWebScrapper[[i,5]] <- duration
}
#URL
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
URL <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_attr('href')
URL <- gsub("/", "https://www.pornhub.com/", URL)
URL <- gsub(" ", "", URL)
dfWebScrapper[[i,6]] <- URL
}
#featuredOn
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[1]/div/a
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[1]/div/a")
title_xpath <- gsub(" ", "", title_xpath)
featuredOn <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
featuredOn <- gsub("  ", "", featuredOn)
featuredOn <- gsub("\n", "", featuredOn)
dfWebScrapper[[i,7]] <- featuredOn
}
#countryID, mostViewed and position
{
dfWebScrapper[[i,8]] <- ID
dfWebScrapper[[i,9]] <- "yearly"
dfWebScrapper[[i,10]] <- i
}
}
WritingToExcel(dfWebScrapper)
print("Yearly done")
}
ReadingCountryAllTime <- function(ID){
print(paste("starting country with", ID, "as ID for all time"))
newID <- paste("https://www.pornhub.com/video?o=mv&t=a&cc=", ID)
newID <- gsub(" ", "", newID)
remDr$navigate(newID)
updated_page_source <- remDr$getPageSource()[[1]]
# Retrieve the updated page's HTML content
updated_page_source <- remDr$getPageSource()[[1]]
# Parse the updated page's HTML using rvest  https://www.theguardian.com/us
dfWebScrapper <- data.frame(date=c(rep.int(Sys.Date(), 30)), title = "", views = "",likeRatio = "", duration = "", URL = "",featuredOn = "", countryID = "", mostViewed="", position=0)
#reading the data,
for (i in 1:30) {
x <- i + 1
#title
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
Title <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
Title <- gsub("  ", "", Title)
Title <- gsub("\n", "", Title)
dfWebScrapper[[i,2]] <- Title
}
#views
{
parsed_page <- read_html(updated_page_source)
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/span/var")
title_xpath <- gsub(" ", "", title_xpath)
views <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
views <- gsub("  ", "", views)
views <- gsub("\n", "", views)
dfWebScrapper[[i,3]] <- views
}
#likeRatio
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[2]/div/div/div
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[2]/div/div/div")
title_xpath <- gsub(" ", "", title_xpath)
likeRatio <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
likeRatio <- gsub("  ", "", likeRatio)
likeRatio <- gsub("\n", "", likeRatio)
dfWebScrapper[[i,4]] <- likeRatio
}
#duration
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[1]/a/div/var
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[1]/a/div/var")
title_xpath <- gsub(" ", "", title_xpath)
duration <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
duration <- gsub("  ", "", duration)
duration <- gsub("\n", "", duration)
dfWebScrapper[[i,5]] <- duration
}
#URL
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/span/a")
title_xpath <- gsub(" ", "", title_xpath)
URL <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_attr('href')
URL <- gsub("/", "https://www.pornhub.com/", URL)
URL <- gsub(" ", "", URL)
dfWebScrapper[[i,6]] <- URL
}
#featuredOn
{
parsed_page <- read_html(updated_page_source) #/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[2]/div/div[3]/div[1]/div/a
title_xpath <- paste("/html/body/div[4]/div[2]/div[5]/div/div[1]/ul/li[", x,"]/div/div[3]/div[1]/div/a")
title_xpath <- gsub(" ", "", title_xpath)
featuredOn <- parsed_page %>%
html_elements(xpath = title_xpath) %>%
html_text()
featuredOn <- gsub("  ", "", featuredOn)
featuredOn <- gsub("\n", "", featuredOn)
dfWebScrapper[[i,7]] <- featuredOn
}
#countryID, mostViewed and position
{
dfWebScrapper[[i,8]] <- ID
dfWebScrapper[[i,9]] <- "allTime"
dfWebScrapper[[i,10]] <- i
}
}
WritingToExcel(dfWebScrapper)
print("All time done")
}
WritingToExcel <- function(dfWebScrapper){
library(openxlsx)
library(readxl)
data <- read_excel("/Users/nikla/OneDrive/Desktop/PHW/PWS/PWS/data/phwMaindt.xlsx")#C:\Users\nikla\OneDrive\Desktop\PHW\PWS\PWS\data\phwMaindt.xlsx
dfWebScrapper <- rbind(dfWebScrapper, data)
write.xlsx(dfWebScrapper, "/Users/nikla/OneDrive/Desktop/PHW/PWS/PWS/data/phwMaindt.xlsx")
}
LoadingPH()
library(RSelenium)
library(wdman)
library(netstat)
library(httr)
library(rvest)
#loading selium and preparing servers dfWebSCrapper[[1,2]]
selenium()
selenium_objext <- selenium(retcommand = T, check = F)
#checking newest version of chrome
binman::list_versions("chromedriver")
#starting a server
rD <- rsDriver(browser="firefox",
chromever = NULL,
verbose =  F,
port = free_port())
